{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.7"
    },
    "colab": {
      "name": "DQN_project_MVA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLey4Lop_ks1",
        "colab_type": "text"
      },
      "source": [
        "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXEBwh0V_ks4",
        "colab_type": "code",
        "outputId": "b384b263-feb1-4d9c-ed8c-40176ec3ce13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "!pip install sk-video \n",
        "import skvideo.io\n",
        "import cv2\n",
        "import json\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras import regularizers as reg\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.optimizers import sgd, adam\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization, Flatten"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sk-video in /usr/local/lib/python3.6/dist-packages (1.1.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sk-video) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sk-video) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7sd04Dp_ks9",
        "colab_type": "text"
      },
      "source": [
        "# MiniProject on Deep Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-biUu83M_ks-",
        "colab_type": "text"
      },
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jimsLnk3_ktA",
        "colab_type": "text"
      },
      "source": [
        "# Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMOzokdq_ktB",
        "colab_type": "text"
      },
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBJUxsrJ_ktC",
        "colab_type": "text"
      },
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU-0-X_z_ktE",
        "colab_type": "text"
      },
      "source": [
        "### The environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZRT6IqN_ktG",
        "colab_type": "text"
      },
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clgqGT-O_ktI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isAE2RZw_ktM",
        "colab_type": "text"
      },
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kprzt4W7_ktN",
        "colab_type": "text"
      },
      "source": [
        "### The Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhLRaGK1_ktO",
        "colab_type": "text"
      },
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65k2Lbs3_ktQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = e\n",
        "\n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiiJQZOq_ktV",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 1__:\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A1mRky2_ktX",
        "colab_type": "text"
      },
      "source": [
        "The function act proposes an action given the current state and all the previous knowledge accumulated.\n",
        "With probability $ \\epsilon $ it returns a random action and with probability $ 1 - \\epsilon $ it returns an action from the current policy. $ \\epsilon $ Allows to explore the different possible actions in order to obtain more information. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJUgrHVm_ktY",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbQfpINy_ktZ",
        "colab_type": "text"
      },
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Jg0zIdg_kta",
        "colab_type": "text"
      },
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd3L5tK2_ktc",
        "colab_type": "text"
      },
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hiq5wvgf_ktd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNkzUmKO_kth",
        "colab_type": "text"
      },
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNyaKrUe_ktj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=40 # set small when debugging\n",
        "epochs_test=10 # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdUB1zMH_kto",
        "colab_type": "text"
      },
      "source": [
        "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgicmUN__ktp",
        "colab_type": "text"
      },
      "source": [
        "- The *position* array allows to store the position of the rat and the possible cells the rat can reach. A cell is set to -1 if the rat can't go to and 0 otherwise..\n",
        "- the *board* array stores the possible rewards on our game grid over time. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZOXM3uf_ktq",
        "colab_type": "text"
      },
      "source": [
        "## Random Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIXVDeFS_ktr",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwKffekT_ktr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def learned_act(self, s):\n",
        "\n",
        "        action = np.random.randint(low=0, high=4) # We pick a random action among: 0, 1, 2 and 3\n",
        "        return action"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fekBxrJQ_ktw",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTgRWocA_kty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(agent, env, epochs, prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "        \n",
        "    for e in range(epochs):\n",
        "        \n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will end\n",
        "        game_over = False\n",
        " \n",
        "        win = 0\n",
        "        lose = 0\n",
        " \n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "    \n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "    \n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "    \n",
        "            # # Apply the reinforcement strategy\n",
        "            if prefix != 'random':\n",
        "                loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        " \n",
        "        # Save as a mp4\n",
        "        if ((e + 1) % 10 == 0) or (e == epochs - 1):\n",
        "            env.draw(prefix+str(e+1))\n",
        "        if prefix != 'random':\n",
        "            agent.save()\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win-lose\n",
        "\n",
        "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
        "              .format(win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZjJgWDY_kt3",
        "colab_type": "code",
        "outputId": "e7091872-a738-423e-ca4a-3637d16cc5e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        }
      },
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "test(agent,env,epochs_test,prefix='random')\n",
        "HTML(display_videos('random' + str(epochs_test) + '.mp4'))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 9.0/16.0. Average score (-7.0)\n",
            "Win/lose count 8.0/8.0. Average score (-3.5)\n",
            "Win/lose count 10.5/11.0. Average score (-2.5)\n",
            "Win/lose count 10.5/7.0. Average score (-1.0)\n",
            "Win/lose count 12.5/9.0. Average score (-0.1)\n",
            "Win/lose count 11.5/19.0. Average score (-1.3333333333333333)\n",
            "Win/lose count 8.5/16.0. Average score (-2.2142857142857144)\n",
            "Win/lose count 7.5/5.0. Average score (-1.625)\n",
            "Win/lose count 8.0/6.0. Average score (-1.2222222222222223)\n",
            "Win/lose count 9.0/10.0. Average score (-1.2)\n",
            "Final score: -1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t09oyK9N_kt8",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzYRFHql_kt8",
        "colab_type": "text"
      },
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "__Question 5__ Let $\\pi$ be a policy, show that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "Finally, deduce that a plausible objective is:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSUtCezJDJlg",
        "colab_type": "text"
      },
      "source": [
        "- 1)\n",
        "\\begin{align*} \n",
        "Q^\\pi(s,a)&=E_{p^{\\pi}}[\\sum_{t=0}^{\\infty}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a]\\\\\n",
        "          &=E_{p^{\\pi}}[r(s_0,a_0) + \\gamma\\sum_{t=1}^{\\infty}\\gamma^{t-1}r(s_{t},a_{t})|s_{0}=s,a_{0}=a]\\\\\n",
        "          &=r(s,a) + \\gamma E_{p^{\\pi}}[\\sum_{t=0}^{\\infty}\\gamma^{t}r(s_{t+1},a_{t+1})|s_{0}=s,a_{0}=a]\\\\\n",
        "          &=r(s,a) + E_{(s',a')\\sim p(.|s,a)}\\left(\\gamma E_{p^{\\pi}}[\\sum_{t=0}^{\\infty}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s',a_{0}=a']\\right)\\\\\n",
        "          &=E_{(s',a')\\sim p(.|s,a)}\\left(r(s,a) + \\gamma E_{p^{\\pi}}[\\sum_{t=0}^{\\infty}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s',a_{0}=a']\\right)\\\\\n",
        "          &=E_{(s',a')\\sim p(.|s,a)}\\left(r(s,a) + \\gamma Q^{\\pi}(s',a') \\right)\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "- 2)\n",
        " Using the optmal greedy policy, which is deterministic; $\\pi^*(s') = arg\\max_{a'} Q^{*}(s',a')$, we have:$$\n",
        "\\begin{align*}\n",
        "Q^*(s,a)&= E_{(s',a')\\sim p(.|s,a)}\\left(r(s,a) + \\gamma Q^{*}(s',a') \\right)\\\\\n",
        "        &= E_{s'\\sim p(.|s,a)\\,and\\,a'\\sim \\pi^*(.|s')}\\left(r(s,a) + \\gamma Q^{*}(s',a') \\right)\\\\\n",
        "        &= E_{s' \\sim \\pi^*(.|s,a)}\\left(r(s,a) + \\gamma \\max_{a'}Q^{*}(s',a') \\right)\\\\\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "- 3)\n",
        "From the previous result, we have:  $$Q^*(s,a)=E_{s' \\sim \\pi^*(.|s,a)}\\left(r(s,a) + \\gamma \\max_{a'}Q^{*}(s',a') \\right)$$\n",
        "\n",
        "By puting everything in the expectation, we have:\n",
        "$$E_{s' \\sim \\pi^*(.|s,a)}\\left(r(s,a) + \\gamma \\max_{a'}Q^{*\n",
        "}(s',a') - Q^{*\n",
        "}(s,a)\\right) = 0$$\n",
        "\n",
        "Then minimizing $\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}$ will allow us to find $Q^*$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOAmYPpg_kt-",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3dDtCTG_kt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory\n",
        "        self.memory = list()\n",
        "\n",
        "    def remember(self, m):\n",
        "        # We append m to memory if the size of memory doesn't exceed max_memory\n",
        "        if len(self.memory) == self.max_memory:\n",
        "            self.memory.pop(0)\n",
        "            self.memory.append(m)\n",
        "        else:\n",
        "            self.memory.append(m)\n",
        "\n",
        "    def random_access(self):\n",
        "        \n",
        "        idx = np.random.randint(low=0, high=len(self.memory)) # We choose a random index\n",
        "        return self.memory[idx]\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KwyKJy7_kuC",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7IM-m53_kuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if (e+1 % 10 == 0) or (e+1==epoch):\n",
        "            env.draw(prefix+str(e+1))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e+1, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKoRB5bH_kuF",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geGjTjC5_kuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(Agent):\n",
        "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
        "        super(DQN, self).__init__(epsilon = epsilon)\n",
        "\n",
        "        # Discount for Q learning\n",
        "        self.discount = 0.99\n",
        "        self.epsilon = epsilon\n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learned_act(self, s):\n",
        "\n",
        "        return np.argmax(self.model.predict(s[None]))\n",
        "\n",
        "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
        "        # Two steps: first memorize the states, second learn from the pool\n",
        "\n",
        "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
        "        \n",
        "        input_states = np.zeros((self.batch_size, 5,5, self.n_state))\n",
        "        target_q = np.zeros((self.batch_size, 4))\n",
        "        \n",
        "        for i in range(self.batch_size):\n",
        "\n",
        "            # we sample a random transition\n",
        "            s, ns, a, r, game_over = self.memory.random_access()\n",
        "            input_states[i], target_q[i] = s, self.model.predict(s[None])\n",
        "            # We have to deal with the case when we are loosing\n",
        "            if game_over:\n",
        "                target_q[i, a] = r\n",
        "            else:\n",
        "                target_q[i, a] =  r + self.discount*np.max(self.model.predict(ns[None]), axis=1)\n",
        "            \n",
        "        \n",
        "        target_q = np.clip(target_q, -3, 3)\n",
        "        l = self.model.train_on_batch(input_states, target_q)\n",
        "\n",
        "        return l\n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)\n",
        "        model.compile(\"adam\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.1,**kwargs):\n",
        "\n",
        "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(36, input_shape=(5*5*self.n_state, ), kernel_regularizer=reg.l2(0.001)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Dense(4))\n",
        "\n",
        "        model.compile(sgd(lr=lr, decay=1e-4), \"mse\")\n",
        "        self.model = model\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYvnfCh__kuM",
        "colab_type": "code",
        "outputId": "51ca4c33-8752-4c05-e723-e7d72f938d0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent, env, epochs_train, prefix='fc_train')\n",
        "HTML(display_videos('fc_train' + str(epochs_train) + '.mp4'))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 001/040 | Loss 0.0497 | Win/lose count 4.0/4.0 (0.0)\n",
            "Epoch 002/040 | Loss 0.0421 | Win/lose count 0.5/2.0 (-1.5)\n",
            "Epoch 003/040 | Loss 0.0421 | Win/lose count 2.0/5.0 (-3.0)\n",
            "Epoch 004/040 | Loss 0.0547 | Win/lose count 5.0/6.0 (-1.0)\n",
            "Epoch 005/040 | Loss 0.0335 | Win/lose count 1.5/1.0 (0.5)\n",
            "Epoch 006/040 | Loss 0.0347 | Win/lose count 5.0/2.0 (3.0)\n",
            "Epoch 007/040 | Loss 0.0351 | Win/lose count 1.0/1.0 (0.0)\n",
            "Epoch 008/040 | Loss 0.0284 | Win/lose count 2.5/5.0 (-2.5)\n",
            "Epoch 009/040 | Loss 0.0269 | Win/lose count 4.5/1.0 (3.5)\n",
            "Epoch 010/040 | Loss 0.0777 | Win/lose count 5.5/6.0 (-0.5)\n",
            "Epoch 011/040 | Loss 0.0279 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 012/040 | Loss 0.0280 | Win/lose count 3.0/6.0 (-3.0)\n",
            "Epoch 013/040 | Loss 0.0223 | Win/lose count 6.0/4.0 (2.0)\n",
            "Epoch 014/040 | Loss 0.0600 | Win/lose count 3.0/5.0 (-2.0)\n",
            "Epoch 015/040 | Loss 0.0194 | Win/lose count 1.5/0 (1.5)\n",
            "Epoch 016/040 | Loss 0.0182 | Win/lose count 3.0/4.0 (-1.0)\n",
            "Epoch 017/040 | Loss 0.0220 | Win/lose count 7.5/2.0 (5.5)\n",
            "Epoch 018/040 | Loss 0.0168 | Win/lose count 4.5/5.0 (-0.5)\n",
            "Epoch 019/040 | Loss 0.0141 | Win/lose count 6.0/6.0 (0.0)\n",
            "Epoch 020/040 | Loss 0.0135 | Win/lose count 7.5/1.0 (6.5)\n",
            "Epoch 021/040 | Loss 0.0140 | Win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 022/040 | Loss 0.0155 | Win/lose count 2.0/2.0 (0.0)\n",
            "Epoch 023/040 | Loss 0.0124 | Win/lose count 5.5/3.0 (2.5)\n",
            "Epoch 024/040 | Loss 0.0116 | Win/lose count 7.0/0 (7.0)\n",
            "Epoch 025/040 | Loss 0.0113 | Win/lose count 7.0/0 (7.0)\n",
            "Epoch 026/040 | Loss 0.0158 | Win/lose count 7.0/3.0 (4.0)\n",
            "Epoch 027/040 | Loss 0.0107 | Win/lose count 9.5/4.0 (5.5)\n",
            "Epoch 028/040 | Loss 0.0666 | Win/lose count 14.5/1.0 (13.5)\n",
            "Epoch 029/040 | Loss 0.0646 | Win/lose count 9.5/2.0 (7.5)\n",
            "Epoch 030/040 | Loss 0.0108 | Win/lose count 10.5/2.0 (8.5)\n",
            "Epoch 031/040 | Loss 0.0086 | Win/lose count 6.0/3.0 (3.0)\n",
            "Epoch 032/040 | Loss 0.0092 | Win/lose count 7.0/1.0 (6.0)\n",
            "Epoch 033/040 | Loss 0.0085 | Win/lose count 6.5/2.0 (4.5)\n",
            "Epoch 034/040 | Loss 0.0064 | Win/lose count 15.5/4.0 (11.5)\n",
            "Epoch 035/040 | Loss 0.0071 | Win/lose count 12.0/0 (12.0)\n",
            "Epoch 036/040 | Loss 0.0089 | Win/lose count 13.0/0 (13.0)\n",
            "Epoch 037/040 | Loss 0.0624 | Win/lose count 12.0/3.0 (9.0)\n",
            "Epoch 038/040 | Loss 0.0075 | Win/lose count 7.0/0 (7.0)\n",
            "Epoch 039/040 | Loss 0.0069 | Win/lose count 6.5/7.0 (-0.5)\n",
            "Epoch 040/040 | Loss 0.0066 | Win/lose count 11.0/3.0 (8.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut6A8AE5_kuP",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WxorNT__kuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args,lr=0.1,**kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(filters=60, kernel_size=3, activation='relu', kernel_regularizer=reg.l2(0.001)))\n",
        "        model.add(Conv2D(filters=30, kernel_size=3, activation='relu', kernel_regularizer=reg.l2(0.001)))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4))\n",
        "        model.compile(sgd(lr=lr, decay=1e-4), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFH28snr_kuU",
        "colab_type": "code",
        "outputId": "44efe2cd-027e-48a2-a52e-2eed1832476c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent,env,epochs_train,prefix='cnn_train')\n",
        "HTML(display_videos('cnn_train' + str(epochs_train) + '.mp4'))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 001/040 | Loss 0.0468 | Win/lose count 3.0/10.0 (-7.0)\n",
            "Epoch 002/040 | Loss 0.0440 | Win/lose count 2.0/1.0 (1.0)\n",
            "Epoch 003/040 | Loss 0.0371 | Win/lose count 3.5/0 (3.5)\n",
            "Epoch 004/040 | Loss 0.0340 | Win/lose count 5.0/3.0 (2.0)\n",
            "Epoch 005/040 | Loss 0.0401 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 006/040 | Loss 0.0437 | Win/lose count 4.0/5.0 (-1.0)\n",
            "Epoch 007/040 | Loss 0.0275 | Win/lose count 2.0/3.0 (-1.0)\n",
            "Epoch 008/040 | Loss 0.0297 | Win/lose count 3.0/3.0 (0.0)\n",
            "Epoch 009/040 | Loss 0.0288 | Win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 010/040 | Loss 0.0258 | Win/lose count 1.5/4.0 (-2.5)\n",
            "Epoch 011/040 | Loss 0.0229 | Win/lose count 5.5/4.0 (1.5)\n",
            "Epoch 012/040 | Loss 0.0265 | Win/lose count 2.5/6.0 (-3.5)\n",
            "Epoch 013/040 | Loss 0.0270 | Win/lose count 3.0/2.0 (1.0)\n",
            "Epoch 014/040 | Loss 0.0220 | Win/lose count 5.0/7.0 (-2.0)\n",
            "Epoch 015/040 | Loss 0.0192 | Win/lose count 4.5/0 (4.5)\n",
            "Epoch 016/040 | Loss 0.0195 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 017/040 | Loss 0.0182 | Win/lose count 6.0/1.0 (5.0)\n",
            "Epoch 018/040 | Loss 0.0187 | Win/lose count 7.5/4.0 (3.5)\n",
            "Epoch 019/040 | Loss 0.0177 | Win/lose count 5.5/1.0 (4.5)\n",
            "Epoch 020/040 | Loss 0.0186 | Win/lose count 9.5/5.0 (4.5)\n",
            "Epoch 021/040 | Loss 0.0152 | Win/lose count 5.5/1.0 (4.5)\n",
            "Epoch 022/040 | Loss 0.0144 | Win/lose count 5.0/0 (5.0)\n",
            "Epoch 023/040 | Loss 0.0126 | Win/lose count 10.5/3.0 (7.5)\n",
            "Epoch 024/040 | Loss 0.0119 | Win/lose count 5.0/2.0 (3.0)\n",
            "Epoch 025/040 | Loss 0.0128 | Win/lose count 15.5/0 (15.5)\n",
            "Epoch 026/040 | Loss 0.0122 | Win/lose count 15.5/4.0 (11.5)\n",
            "Epoch 027/040 | Loss 0.0110 | Win/lose count 10.5/5.0 (5.5)\n",
            "Epoch 028/040 | Loss 0.0110 | Win/lose count 17.0/3.0 (14.0)\n",
            "Epoch 029/040 | Loss 0.0109 | Win/lose count 8.0/0 (8.0)\n",
            "Epoch 030/040 | Loss 0.0103 | Win/lose count 14.0/2.0 (12.0)\n",
            "Epoch 031/040 | Loss 0.0154 | Win/lose count 7.0/3.0 (4.0)\n",
            "Epoch 032/040 | Loss 0.0092 | Win/lose count 7.5/1.0 (6.5)\n",
            "Epoch 033/040 | Loss 0.0180 | Win/lose count 20.5/7.0 (13.5)\n",
            "Epoch 034/040 | Loss 0.0629 | Win/lose count 12.5/0 (12.5)\n",
            "Epoch 035/040 | Loss 0.0084 | Win/lose count 16.5/2.0 (14.5)\n",
            "Epoch 036/040 | Loss 0.0142 | Win/lose count 10.5/2.0 (8.5)\n",
            "Epoch 037/040 | Loss 0.0146 | Win/lose count 15.5/3.0 (12.5)\n",
            "Epoch 038/040 | Loss 0.0076 | Win/lose count 22.0/1.0 (21.0)\n",
            "Epoch 039/040 | Loss 0.0106 | Win/lose count 18.5/2.0 (16.5)\n",
            "Epoch 040/040 | Loss 0.0077 | Win/lose count 12.5/9.0 (3.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3eCW6XG_kuW",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RinZu7_l_kuY",
        "colab_type": "code",
        "outputId": "8d3848c8-d77c-492c-95ed-257a99476ebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T,temperature=0.3)\n",
        "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
        "\n",
        "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
        "print('Test of the CNN')\n",
        "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
        "print('Test of the FC')\n",
        "test(agent_fc,env,epochs_test,prefix='fc_test')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test of the CNN\n",
            "Win/lose count 5.0/1.0. Average score (4.0)\n",
            "Win/lose count 6.0/3.0. Average score (3.5)\n",
            "Win/lose count 20.5/4.0. Average score (7.833333333333333)\n",
            "Win/lose count 9.0/6.0. Average score (6.625)\n",
            "Win/lose count 13.5/4.0. Average score (7.2)\n",
            "Win/lose count 6.0/4.0. Average score (6.333333333333333)\n",
            "Win/lose count 9.5/2.0. Average score (6.5)\n",
            "Win/lose count 5.0/3.0. Average score (5.9375)\n",
            "Win/lose count 13.5/0. Average score (6.777777777777778)\n",
            "Win/lose count 13.0/1.0. Average score (7.3)\n",
            "Final score: 7.3\n",
            "Test of the FC\n",
            "Win/lose count 4.5/0. Average score (4.5)\n",
            "Win/lose count 8.0/18.0. Average score (-2.75)\n",
            "Win/lose count 5.0/7.0. Average score (-2.5)\n",
            "Win/lose count 8.0/7.0. Average score (-1.625)\n",
            "Win/lose count 4.5/4.0. Average score (-1.2)\n",
            "Win/lose count 3.0/0. Average score (-0.5)\n",
            "Win/lose count 3.0/6.0. Average score (-0.8571428571428571)\n",
            "Win/lose count 6.5/3.0. Average score (-0.3125)\n",
            "Win/lose count 4.5/0. Average score (0.2222222222222222)\n",
            "Win/lose count 12.0/5.0. Average score (0.9)\n",
            "Final score: 0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jQkMnFt_kud",
        "colab_type": "code",
        "outputId": "f994e7f3-c43d-4151-bb12-a741d9e8de08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "HTML(display_videos('cnn_test' + str(epochs_test) + '.mp4'))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_Q8Y8bW_kuf",
        "colab_type": "code",
        "outputId": "8048a21d-5035-4d17-ea79-df26fc0693f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "HTML(display_videos('fc_test' + str(epochs_test) + '.mp4'))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52E2hHYT_kui",
        "colab_type": "text"
      },
      "source": [
        "- Both agents get easily stuck when there is no more \"cheese\" (reward) near the agent. \n",
        "- We don't explore enough the map so we tend to exploit what we already know, that explains why the agent gets stuck.\n",
        "\n",
        "- Increasing the temperature leads to a grid with a higher number of \"cheese cells\" compared to poisonous cells. The agent explores more and has a highest score since there are a lot more positive rewards on his path than negative ones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA46J6rp_kuj",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqbhyVC8a_Ww",
        "colab_type": "text"
      },
      "source": [
        "- We will make $ \\epsilon $ decrease from a factor $ \\gamma $ (between 0 and 1) at each epoch in order to explore a lot at the beginning to gain knowledge and then to exploit the optimal policy we find."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKqOe2PK_kuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_explore(agent,env,epoch, gamma=0.8, prefix=''):\n",
        "    \n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "    \n",
        "    min_eps = 0.1 # minimum value of epsilon\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # New epsilon\n",
        "        if e >= 1:\n",
        "            new_eps = max(min_eps, agent.epsilon*gamma)\n",
        "            agent.set_epsilon(new_eps)\n",
        "        # This assumes that the games will end\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "    \n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "    \n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose - reward\n",
        "            \n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "        \n",
        "        \n",
        "        # Save as a mp4\n",
        "        if (e+1 % 10 == 0) or (e == epoch - 1):\n",
        "            env.draw(prefix + str(e+1))\n",
        "    \n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "    \n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({}) | epsilon: {}\"\n",
        "              .format(e+1, epoch, loss, win, lose, win-lose, agent.epsilon))\n",
        "        agent.save(name_weights=prefix+'model.h5', name_model=prefix+'model.json')\n",
        "        \n",
        "\n",
        "class EnvironmentExploring(Environment):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        super(EnvironmentExploring, self).__init__(grid_size=grid_size,\n",
        "                                                   max_time=max_time,\n",
        "                                                   temperature=temperature)\n",
        "        self.malus_position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "    def draw(self, e):\n",
        "        super(EnvironmentExploring, self).draw(e)\n",
        "    \n",
        "    def get_frame(self, t):\n",
        "        super(EnvironmentExploring, self).get_frame(t)\n",
        "    \n",
        "    def act(self, action, train=False):\n",
        "\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = 0\n",
        "        if train:\n",
        "             reward = -self.malus_position[self.x, self.y]\n",
        "        \n",
        "        reward += self.board[self.x, self.y]\n",
        "        self.malus_position[self.x, self.y] = 0.1\n",
        "\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        \n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "\n",
        "        return state, reward, game_over\n",
        "    \n",
        "    def reset(self):\n",
        "        \n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        self.malus_position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.malus_position[self.x, self.y] = 0.1\n",
        "\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        \n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "\n",
        "        return state\n",
        "\n",
        "    \n",
        "# ## use those samples of code:\n",
        "# #In train explore:\n",
        "# state, reward, game_over = env.act(action, train=True)\n",
        "\n",
        "# ## In Environment exploring:\n",
        "# # You will have to change n_state to 3 because you will use one more layer!\n",
        "# reward = 0\n",
        "# if train:\n",
        "#     reward = -self.malus_position[self.x, self.y]\n",
        "# self.malus_position[self.x, self.y] = 0.1\n",
        "\n",
        "# reward = reward + self.board[self.x, self.y]\n",
        "# # 3 \"feature\" states instead of 2\n",
        "# state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "#                                 self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "#                         self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFIGahz6_ku5",
        "colab_type": "code",
        "outputId": "0868974c-f4e0-4430-a663-93849922c9da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        }
      },
      "source": [
        "# Training\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 1, memory_size=2000, batch_size = 32,n_state=3)\n",
        "train_explore(agent, env, epochs_train, gamma=0.8, prefix='cnn_train_explore')\n",
        "HTML(display_videos('cnn_train_explore' + str(epochs_train) + '.mp4'))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 001/040 | Loss 0.0585 | Win/lose count 12.0/14.0 (-2.0) | epsilon: 1\n",
            "Epoch 002/040 | Loss 0.0495 | Win/lose count 8.5/10.0 (-1.5) | epsilon: 0.8\n",
            "Epoch 003/040 | Loss 0.0436 | Win/lose count 9.5/11.0 (-1.5) | epsilon: 0.6400000000000001\n",
            "Epoch 004/040 | Loss 0.1040 | Win/lose count 14.5/10.0 (4.5) | epsilon: 0.5120000000000001\n",
            "Epoch 005/040 | Loss 0.0382 | Win/lose count 12.5/7.0 (5.5) | epsilon: 0.40960000000000013\n",
            "Epoch 006/040 | Loss 0.0920 | Win/lose count 18.0/12.0 (6.0) | epsilon: 0.32768000000000014\n",
            "Epoch 007/040 | Loss 0.0307 | Win/lose count 6.5/4.0 (2.5) | epsilon: 0.2621440000000001\n",
            "Epoch 008/040 | Loss 0.0353 | Win/lose count 12.0/5.0 (7.0) | epsilon: 0.2097152000000001\n",
            "Epoch 009/040 | Loss 0.0343 | Win/lose count 15.0/3.0 (12.0) | epsilon: 0.1677721600000001\n",
            "Epoch 010/040 | Loss 0.1284 | Win/lose count 15.5/2.0 (13.5) | epsilon: 0.13421772800000006\n",
            "Epoch 011/040 | Loss 0.0246 | Win/lose count 9.5/1.0 (8.5) | epsilon: 0.10737418240000006\n",
            "Epoch 012/040 | Loss 0.0271 | Win/lose count 5.0/1.0 (4.0) | epsilon: 0.1\n",
            "Epoch 013/040 | Loss 0.0224 | Win/lose count 4.0/0 (4.0) | epsilon: 0.1\n",
            "Epoch 014/040 | Loss 0.0204 | Win/lose count 17.5/2.0 (15.5) | epsilon: 0.1\n",
            "Epoch 015/040 | Loss 0.0196 | Win/lose count 14.5/3.0 (11.5) | epsilon: 0.1\n",
            "Epoch 016/040 | Loss 0.0716 | Win/lose count 19.5/2.0 (17.5) | epsilon: 0.1\n",
            "Epoch 017/040 | Loss 0.0764 | Win/lose count 7.5/1.0 (6.5) | epsilon: 0.1\n",
            "Epoch 018/040 | Loss 0.0661 | Win/lose count 5.5/1.0 (4.5) | epsilon: 0.1\n",
            "Epoch 019/040 | Loss 0.0157 | Win/lose count 2.5/2.0 (0.5) | epsilon: 0.1\n",
            "Epoch 020/040 | Loss 0.0154 | Win/lose count 13.0/1.0 (12.0) | epsilon: 0.1\n",
            "Epoch 021/040 | Loss 0.0141 | Win/lose count 18.0/4.0 (14.0) | epsilon: 0.1\n",
            "Epoch 022/040 | Loss 0.0137 | Win/lose count 14.0/2.0 (12.0) | epsilon: 0.1\n",
            "Epoch 023/040 | Loss 0.0158 | Win/lose count 13.0/3.0 (10.0) | epsilon: 0.1\n",
            "Epoch 024/040 | Loss 0.0126 | Win/lose count 7.0/2.0 (5.0) | epsilon: 0.1\n",
            "Epoch 025/040 | Loss 0.0131 | Win/lose count 9.5/0 (9.5) | epsilon: 0.1\n",
            "Epoch 026/040 | Loss 0.0120 | Win/lose count 7.0/3.0 (4.0) | epsilon: 0.1\n",
            "Epoch 027/040 | Loss 0.0129 | Win/lose count 7.5/1.0 (6.5) | epsilon: 0.1\n",
            "Epoch 028/040 | Loss 0.0168 | Win/lose count 15.5/4.0 (11.5) | epsilon: 0.1\n",
            "Epoch 029/040 | Loss 0.0115 | Win/lose count 10.0/1.0 (9.0) | epsilon: 0.1\n",
            "Epoch 030/040 | Loss 0.0160 | Win/lose count 11.5/2.0 (9.5) | epsilon: 0.1\n",
            "Epoch 031/040 | Loss 0.0101 | Win/lose count 13.5/0 (13.5) | epsilon: 0.1\n",
            "Epoch 032/040 | Loss 0.0118 | Win/lose count 14.0/5.0 (9.0) | epsilon: 0.1\n",
            "Epoch 033/040 | Loss 0.0615 | Win/lose count 15.5/1.0 (14.5) | epsilon: 0.1\n",
            "Epoch 034/040 | Loss 0.0149 | Win/lose count 17.5/5.0 (12.5) | epsilon: 0.1\n",
            "Epoch 035/040 | Loss 0.0626 | Win/lose count 13.0/3.0 (10.0) | epsilon: 0.1\n",
            "Epoch 036/040 | Loss 0.0101 | Win/lose count 9.0/0 (9.0) | epsilon: 0.1\n",
            "Epoch 037/040 | Loss 0.0079 | Win/lose count 15.5/2.0 (13.5) | epsilon: 0.1\n",
            "Epoch 038/040 | Loss 0.0092 | Win/lose count 12.5/4.0 (8.5) | epsilon: 0.1\n",
            "Epoch 039/040 | Loss 0.0074 | Win/lose count 15.0/5.0 (10.0) | epsilon: 0.1\n",
            "Epoch 040/040 | Loss 0.0090 | Win/lose count 6.5/2.0 (4.5) | epsilon: 0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGqPCTsC_ku9",
        "colab_type": "code",
        "outputId": "ef152add-c3f3-454e-b2e6-71edd9e14f6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        }
      },
      "source": [
        "# Evaluation\n",
        "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
        "HTML(display_videos('cnn_test_explore' + str(epochs_test) + '.mp4'))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 11.0/3.0. Average score (8.0)\n",
            "Win/lose count 7.0/1.0. Average score (7.0)\n",
            "Win/lose count 24.5/2.0. Average score (12.166666666666666)\n",
            "Win/lose count 7.0/2.0. Average score (10.375)\n",
            "Win/lose count 14.0/0. Average score (11.1)\n",
            "Win/lose count 19.0/1.0. Average score (12.25)\n",
            "Win/lose count 12.0/0. Average score (12.214285714285714)\n",
            "Win/lose count 11.0/2.0. Average score (11.8125)\n",
            "Win/lose count 13.0/2.0. Average score (11.722222222222221)\n",
            "Win/lose count 10.0/3.0. Average score (11.25)\n",
            "Final score: 11.25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGHaYRxCOHWH",
        "colab_type": "text"
      },
      "source": [
        "- We observe an important difference of performance compared to the previous case without an adaptative epsilon (For the same number of epochs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSm7R-sm_kvB",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-DPvVOy_kvC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4wJr5FW_kvD",
        "colab_type": "text"
      },
      "source": [
        "***"
      ]
    }
  ]
}